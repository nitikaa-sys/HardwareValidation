{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc611160",
   "metadata": {},
   "source": [
    "# Online Hardware Validation - ADS1299\n",
    "\n",
    "Live acquisition and analysis using the acquisition and analysis modules.\n",
    "\n",
    "**Architecture:**\n",
    "- `acquisition.HardwareClient` - ESP32/ADS1299 communication\n",
    "- `acquisition.capture_live_stream()` - WebSocket frame streaming\n",
    "- `analysis.parse_framestream_bin()` - Binary parsing\n",
    "- `analysis.preprocess` - Signal processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Apply nest_asyncio for Jupyter compatibility\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import from our modules\n",
    "from acquisition import HardwareClient, capture_live_stream\n",
    "from analysis import parse_framestream_bin, counts_to_uv, preprocess_channel_uv, FS_HZ, VREF_V, GAIN\n",
    "from analysis.timing_integrity import check_timing_integrity\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# Configuration\n",
    "ESP32_IP = \"node.local\"\n",
    "CAPTURE_DURATION_S = 5.0\n",
    "FS = 16000  # Hz\n",
    "\n",
    "# Channel definitions\n",
    "EEG_CHANNELS = [1, 2, 3]\n",
    "OAE_CHANNELS = [4, 5]\n",
    "N_CHANNELS = 8\n",
    "\n",
    "print(f\"ESP32 IP: {ESP32_IP}\")\n",
    "print(f\"Capture duration: {CAPTURE_DURATION_S}s\")\n",
    "print(f\"Sample rate: {FS} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utilities-section",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_welch(x_uv, fs, nperseg=512):\n",
    "    \"\"\"Compute Welch PSD.\"\"\"\n",
    "    return signal.welch(x_uv, fs, nperseg=nperseg)\n",
    "\n",
    "def fft_dbfs(x_uv, fs, vref=VREF_V, gain=GAIN):\n",
    "    \"\"\"FFT magnitude in dBFS.\"\"\"\n",
    "    from scipy.fft import rfft, rfftfreq\n",
    "    x_uv = np.asarray(x_uv, dtype=float)\n",
    "    n = len(x_uv)\n",
    "    volts = x_uv * 1e-6\n",
    "    spec = rfft(volts)\n",
    "    amp = (2.0 / n) * np.abs(spec)\n",
    "    amp[0] /= 2.0\n",
    "    fullscale = vref / gain\n",
    "    dbfs = 20 * np.log10(amp / fullscale + 1e-20)\n",
    "    freqs = rfftfreq(n, 1/fs)\n",
    "    return freqs, np.minimum(dbfs, 0)\n",
    "\n",
    "def saturation_report(counts: np.ndarray, adc_bits: int = 24) -> None:\n",
    "    \"\"\"Check for ADC saturation/railing.\"\"\"\n",
    "    lo = -2**(adc_bits-1)\n",
    "    hi = 2**(adc_bits-1) - 1\n",
    "    print(f\"\\n{adc_bits}-bit ADC rails: [{lo}, {hi}]\")\n",
    "    for ch in range(counts.shape[0]):\n",
    "        x = counts[ch]\n",
    "        sat_lo = int(np.sum(x == lo))\n",
    "        sat_hi = int(np.sum(x == hi))\n",
    "        print(f\"Ch{ch+1:<2}  min={int(x.min()):>9}  max={int(x.max()):>9}  sat_lo={sat_lo:>6}  sat_hi={sat_hi:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_summary(uv, channels, fs_hz, title=\"Hardware Validation\"):\n",
    "    \"\"\"\n",
    "    Plot validation summary: time series, histogram, PSD, FFT.\n",
    "    \"\"\"\n",
    "    n_ch, n_samples = uv.shape\n",
    "    t = np.arange(n_samples) / fs_hz\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(f\"{title} | {n_samples} samples @ {fs_hz} Hz\", fontsize=14)\n",
    "    ax_ts, ax_hist, ax_psd, ax_fft = axes.flatten()\n",
    "    \n",
    "    # Time series\n",
    "    for i in range(n_ch):\n",
    "        ax_ts.plot(t, uv[i], label=f\"Ch{channels[i]}\")\n",
    "    ax_ts.set_title(\"Time Series\")\n",
    "    ax_ts.set_xlabel(\"Time (s)\")\n",
    "    ax_ts.set_ylabel(\"uV\")\n",
    "    ax_ts.legend()\n",
    "    ax_ts.grid(alpha=0.3)\n",
    "    \n",
    "    # Histogram\n",
    "    for i in range(n_ch):\n",
    "        ax_hist.hist(uv[i], bins=100, alpha=0.5, label=f\"Ch{channels[i]}\")\n",
    "    ax_hist.set_title(\"Amplitude Distribution\")\n",
    "    ax_hist.set_xlabel(\"uV\")\n",
    "    ax_hist.set_ylabel(\"Count\")\n",
    "    ax_hist.legend()\n",
    "    ax_hist.grid(alpha=0.3)\n",
    "    \n",
    "    # PSD\n",
    "    for i in range(n_ch):\n",
    "        f, psd = psd_welch(uv[i], fs_hz)\n",
    "        ax_psd.semilogy(f, psd, label=f\"Ch{channels[i]}\")\n",
    "    ax_psd.set_title(\"PSD (Welch)\")\n",
    "    ax_psd.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax_psd.set_ylabel(\"PSD (uV^2/Hz)\")\n",
    "    ax_psd.set_xlim(0, min(200, fs_hz/2))\n",
    "    ax_psd.legend()\n",
    "    ax_psd.grid(alpha=0.3)\n",
    "    \n",
    "    # FFT dBFS\n",
    "    for i in range(n_ch):\n",
    "        f, dbfs = fft_dbfs(uv[i], fs_hz)\n",
    "        ax_fft.plot(f, dbfs, label=f\"Ch{channels[i]}\")\n",
    "    ax_fft.set_title(\"FFT (dBFS)\")\n",
    "    ax_fft.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax_fft.set_ylabel(\"dBFS\")\n",
    "    ax_fft.set_xlim(0, min(200, fs_hz/2))\n",
    "    ax_fft.set_ylim(-120, 5)\n",
    "    ax_fft.axhline(0, color='black', linestyle='--')\n",
    "    ax_fft.legend()\n",
    "    ax_fft.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquire-section",
   "metadata": {},
   "source": [
    "## Live Acquisition\n",
    "\n",
    "Single function using `acquisition.capture_live_stream()` and `analysis.parse_framestream_bin()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquire-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_and_parse(\n",
    "    duration_s: float = CAPTURE_DURATION_S,\n",
    "    channels: list = None,\n",
    "    apply_notch: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Acquire live data and parse using modules.\n",
    "    \n",
    "    Returns:\n",
    "        counts: (n_channels, n_samples) raw ADC counts\n",
    "        uv: (len(channels), n_samples) preprocessed uV\n",
    "        info: capture info dict with timing headers\n",
    "    \"\"\"\n",
    "    if channels is None:\n",
    "        channels = list(range(1, N_CHANNELS + 1))\n",
    "    \n",
    "    # Create hardware client\n",
    "    client = HardwareClient(ESP32_IP)\n",
    "    \n",
    "    # Detect sample rate from registers\n",
    "    sample_rate = client.detect_sample_rate()\n",
    "    if sample_rate is None:\n",
    "        print(f\"Could not detect sample rate, using default: {FS}\")\n",
    "        sample_rate = FS\n",
    "    print(f\"Sample rate: {sample_rate} Hz\")\n",
    "    \n",
    "    # Capture live stream\n",
    "    sample_bytes, raw_frames_bytes, info = asyncio.run(\n",
    "        capture_live_stream(client, duration_s, sample_rate)\n",
    "    )\n",
    "    \n",
    "    # Parse using analysis module\n",
    "    counts, meta = parse_framestream_bin(raw_frames_bytes)\n",
    "    print(f\"Parsed counts shape: {counts.shape}\")\n",
    "    \n",
    "    # Check timing integrity\n",
    "    if 'hdr' in info:\n",
    "        print(\"\\n=== Timing Integrity ===\")\n",
    "        n_frames = len(info['hdr']['t1_first_drdy_us'])\n",
    "        print(f\"Frames received: {n_frames}\")\n",
    "        print(f\"Samples parsed: {counts.shape[1]}\")\n",
    "    \n",
    "    # Saturation check\n",
    "    print(\"\\n=== Saturation Check ===\")\n",
    "    saturation_report(counts)\n",
    "    \n",
    "    # Preprocess selected channels\n",
    "    ch_indices = [ch - 1 for ch in channels]\n",
    "    counts_selected = counts[ch_indices, :]\n",
    "    \n",
    "    uv = np.vstack([\n",
    "        preprocess_channel_uv(counts_selected[i], sample_rate, apply_notch=apply_notch)\n",
    "        for i in range(len(channels))\n",
    "    ])\n",
    "    \n",
    "    return counts_selected, uv, channels, sample_rate, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tests-section",
   "metadata": {},
   "source": [
    "## Validation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-noise",
   "metadata": {},
   "source": [
    "### A2: Internal ADC Noise (Inputs Shorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-internal-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_internal_noise(channels=None, apply_notch=False):\n",
    "    \"\"\"Internal ADC noise test with inputs shorted.\"\"\"\n",
    "    if channels is None:\n",
    "        channels = EEG_CHANNELS\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"A2: Internal ADC Noise (Inputs Shorted)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    counts, uv, used_channels, fs_hz, info = acquire_and_parse(\n",
    "        duration_s=CAPTURE_DURATION_S,\n",
    "        channels=channels,\n",
    "        apply_notch=apply_notch\n",
    "    )\n",
    "    \n",
    "    if counts.shape[1] == 0:\n",
    "        print(\"No samples received - device not ready\")\n",
    "        return\n",
    "    \n",
    "    plot_validation_summary(uv, used_channels, fs_hz, title=\"A2: Internal ADC Noise\")\n",
    "    print(\"Internal noise test complete.\")\n",
    "\n",
    "# Run:\n",
    "run_internal_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-noise",
   "metadata": {},
   "source": [
    "### A1: Environmental Noise (Floating Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-floating-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_floating_noise(channels=None, apply_notch=False):\n",
    "    \"\"\"Environmental noise test with floating inputs.\"\"\"\n",
    "    if channels is None:\n",
    "        channels = EEG_CHANNELS\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"A1: Environmental Noise (Floating Inputs)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    counts, uv, used_channels, fs_hz, info = acquire_and_parse(\n",
    "        duration_s=CAPTURE_DURATION_S,\n",
    "        channels=channels,\n",
    "        apply_notch=apply_notch\n",
    "    )\n",
    "    \n",
    "    if counts.shape[1] == 0:\n",
    "        print(\"No samples received - device not ready\")\n",
    "        return\n",
    "    \n",
    "    plot_validation_summary(uv, used_channels, fs_hz, title=\"A1: Floating Inputs\")\n",
    "    print(\"Floating noise test complete.\")\n",
    "\n",
    "# Run:\n",
    "run_floating_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injected-signal",
   "metadata": {},
   "source": [
    "### B1: Injected Signal Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-injected-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_injected_signal(channels=None, apply_notch=False):\n",
    "    \"\"\"Injected signal test.\"\"\"\n",
    "    if channels is None:\n",
    "        channels = EEG_CHANNELS\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"B1: Injected Signal Test\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    counts, uv, used_channels, fs_hz, info = acquire_and_parse(\n",
    "        duration_s=CAPTURE_DURATION_S,\n",
    "        channels=channels,\n",
    "        apply_notch=apply_notch\n",
    "    )\n",
    "    \n",
    "    if counts.shape[1] == 0:\n",
    "        print(\"No samples received - device not ready\")\n",
    "        return\n",
    "    \n",
    "    plot_validation_summary(uv, used_channels, fs_hz, title=\"B1: Injected Signal\")\n",
    "    print(\"Injected signal test complete.\")\n",
    "\n",
    "# Run:\n",
    "# run_injected_signal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-eeg",
   "metadata": {},
   "source": [
    "### Functional EEG: Eyes Open vs Eyes Closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-functional-eeg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_functional_eeg(channels=None, apply_notch=True):\n",
    "    \"\"\"Functional EEG test: Eyes Open vs Eyes Closed.\"\"\"\n",
    "    if channels is None:\n",
    "        channels = EEG_CHANNELS\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Functional EEG: Eyes Open vs Eyes Closed\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Eyes Open\n",
    "    print(\"\\n--- Eyes OPEN ---\")\n",
    "    input(\"Press Enter when ready for Eyes Open recording...\")\n",
    "    counts_eo, uv_eo, ch_eo, fs_eo, info_eo = acquire_and_parse(\n",
    "        duration_s=CAPTURE_DURATION_S,\n",
    "        channels=channels,\n",
    "        apply_notch=apply_notch\n",
    "    )\n",
    "    \n",
    "    # Eyes Closed\n",
    "    print(\"\\n--- Eyes CLOSED ---\")\n",
    "    input(\"Press Enter when ready for Eyes Closed recording...\")\n",
    "    counts_ec, uv_ec, ch_ec, fs_ec, info_ec = acquire_and_parse(\n",
    "        duration_s=CAPTURE_DURATION_S,\n",
    "        channels=channels,\n",
    "        apply_notch=apply_notch\n",
    "    )\n",
    "    \n",
    "    if uv_eo.shape[1] == 0 or uv_ec.shape[1] == 0:\n",
    "        print(\"No samples received - device not ready\")\n",
    "        return\n",
    "    \n",
    "    # Compute PSDs for first channel\n",
    "    f_eo, psd_eo = psd_welch(uv_eo[0], fs_eo)\n",
    "    f_ec, psd_ec = psd_welch(uv_ec[0], fs_ec)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # PSD comparison\n",
    "    axes[0].semilogy(f_eo, psd_eo, label='Eyes Open')\n",
    "    axes[0].semilogy(f_ec, psd_ec, label='Eyes Closed')\n",
    "    axes[0].set_xlim(0, 50)\n",
    "    axes[0].set_xlabel('Frequency (Hz)')\n",
    "    axes[0].set_ylabel('PSD (uV^2/Hz)')\n",
    "    axes[0].set_title(f'PSD Comparison - Ch{channels[0]}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Alpha band power comparison\n",
    "    alpha_mask_eo = (f_eo >= 8) & (f_eo <= 13)\n",
    "    alpha_mask_ec = (f_ec >= 8) & (f_ec <= 13)\n",
    "    alpha_power_eo = np.trapz(psd_eo[alpha_mask_eo], f_eo[alpha_mask_eo])\n",
    "    alpha_power_ec = np.trapz(psd_ec[alpha_mask_ec], f_ec[alpha_mask_ec])\n",
    "    \n",
    "    axes[1].bar(['Eyes Open', 'Eyes Closed'], [alpha_power_eo, alpha_power_ec])\n",
    "    axes[1].set_ylabel('Alpha Power (8-13 Hz) uV^2')\n",
    "    axes[1].set_title('Alpha Band Power Comparison')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAlpha power (8-13 Hz):\")\n",
    "    print(f\"  Eyes Open:   {alpha_power_eo:.2f} uV^2\")\n",
    "    print(f\"  Eyes Closed: {alpha_power_ec:.2f} uV^2\")\n",
    "    print(f\"  Ratio (EC/EO): {alpha_power_ec/alpha_power_eo:.2f}x\")\n",
    "    print(\"\\nFunctional EEG test complete.\")\n",
    "\n",
    "# Run:\n",
    "# run_functional_eeg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
